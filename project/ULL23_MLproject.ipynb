{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mhuertascompany/ULL_2022/blob/main/project/ULL22_MLproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQFb4MCH9uSp"
   },
   "source": [
    "Do not forget to select a GPU Runtime before starting. \n",
    "\n",
    "The goal of this project is to perform simulation based inference with deep learning to constrain cosmological parameters. We will use the [CAMELS project](https://www.camel-simulations.org/). The Cosmology and Astrophysics with Machine Learning Simulations (CAMELS) is a suite of cosmological simulations with varying comsologies and subgrid physics, specially desgined for training Machine Learnning models. \n",
    "\n",
    "For this exercice we are going to use the [Multifield dataset](https://camels-multifield-dataset.readthedocs.io/en/latest/), which consists of a series of 2D Maps of different quantities (Stellar Mass, Total Mass, Gas Temperature, Velocity ...) for different cosmologies and subgrid parameters. \n",
    "\n",
    "**You will present the results in a pdf document together with a link to the code you used to generate the different plots.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZwdb07rkvd5"
   },
   "source": [
    "# Connect to GCloud\n",
    "\n",
    "Just run these cells. Do not modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYE1KeFi0SGf"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "!gcloud config set project candels-270716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdAp9WWy0p-r"
   },
   "outputs": [],
   "source": [
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!apt -qq update\n",
    "!apt -qq install gcsfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cUIWcrk0uZN"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!gcsfuse --implicit-dirs -o allow_other -file-mode=777 -dir-mode=777 camels data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6wDbQGR7yem"
   },
   "source": [
    "# Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aca2I0Z60zOm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import sklearn\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "plt.style.use(astropy_mpl_style)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pv9qDIW_71tx"
   },
   "source": [
    "#Load Maps and Corresponding parameters\n",
    "The maps can be changed.\n",
    "\n",
    "The models can be: \n",
    " - IllustrisTNG\n",
    " -  SIMBA\n",
    "\n",
    "The map types can be:\n",
    "-  T (Gas Temperature)\n",
    "-  Mstar (stellar mass)\n",
    "- Z (Metallicity) \n",
    "-  Mgas (Gas Mass)\n",
    "- Vgas (Gas Velocity)\n",
    "- Mtot (total mass) etc..\n",
    "\n",
    "THe list of available files is in /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT8s4KZ705Rq"
   },
   "outputs": [],
   "source": [
    "## This function loads the maps and corresponding parameters\n",
    "\n",
    "def load_maps(model,maptype):\n",
    "\n",
    "  fmaps = '/content/data/Maps_'+maptype+'_'+model+'_LH_z=0.00.npy'\n",
    "  maps  = np.load(fmaps)\n",
    "  fparams = '/content/data/params_'+model+'.txt'\n",
    "  params  = np.loadtxt(fparams)\n",
    "  return maps,params\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dUWy_D62bfH"
   },
   "outputs": [],
   "source": [
    "# loads the temperature map of Illustris TNG - can take a while\n",
    "maps, params = load_maps('IllustrisTNG','T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZP4c__TelPB"
   },
   "source": [
    "The following cell shows a random example of the loaded map together with the corresponding parameters. You can run it several times. The goal is to design a deep learning model to infer cosmological and astrophysical parameters using the different maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xIeiIgh1kQh"
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "map_number = randrange(15000)\n",
    "plt.imshow(np.log10(maps[map_number]),cmap=plt.get_cmap('binary_r'), origin='lower', interpolation='bicubic')\n",
    "plt.show()\n",
    "params_map = params[map_number//15] ## This is how params and maps are connected. \n",
    "print('Value of the parameters for this map')\n",
    "print('Omega_m: %.5f'%params_map[0])\n",
    "print('sigma_8: %.5f'%params_map[1])\n",
    "print('A_SN1:   %.5f'%params_map[2])\n",
    "print('A_AGN1:  %.5f'%params_map[3])\n",
    "print('A_SN2:   %.5f'%params_map[4])\n",
    "print('A_AGN2:  %.5f'%params_map[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2DIjO1tgQbt"
   },
   "source": [
    "# Exercice 1: \n",
    "Create a Convolutional Neural Network that takes as input the map of gas temperature (T) from the IllustrisTNG model loaded in the and estimates $\\Omega_m$, the Dark Matter Density. The output of the Neural Network should be a Gaussian Probability Density Function. You can also experiment with multimodal Gaussians (see build_model() function defined below).\n",
    "\n",
    "You will produce:\n",
    "- A summary of the architecture used. \n",
    "\n",
    "     --> For this see plot_model() function from keras.utils.vis_utils and visualkeras libraries.\n",
    "     \n",
    "     \n",
    "- A plot of the learning history including the trainng and the validation sets.\n",
    "\n",
    "     --> You can use ideas from previous exercises (epochs vs. Loss).\n",
    "     \n",
    "     \n",
    "- A plot of input vs. output on the test set, including error bars. You will use the mean of posterior as output.\n",
    "\n",
    "     --> Real vs mean prediction for the test set, plot the identity function to compare.\n",
    "     \n",
    "     \n",
    "- Ten example plots of posterior distributions, together with the ground truth.\n",
    "\n",
    "\n",
    "- 1-sigma value of the posterior versus the true error for the test set. Does the posterior properly capture uncertainty? Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define negative log likelihood loss\n",
    "\n",
    "negloglik = lambda y, p_y: -p_y.log_prob(y)\n",
    "\n",
    "def build_model(nfilters,num_components,input_shape,output_shape):\n",
    "  cnn = tfk.Sequential([\n",
    "  tfkl.Conv2D(\n",
    "      nfilters, (4,4),\n",
    "      input_shape=(input_shape,input_shape,1),\n",
    "      padding=\"same\",\n",
    "      activation='relu'),\n",
    "  tfkl.BatchNormalization(),\n",
    "  tfkl.MaxPool2D((2,2),strides=2),\n",
    "  tfkl.Conv2D(\n",
    "      nfilters*2, (3,3),\n",
    "      padding=\"same\",\n",
    "      activation='relu'),\n",
    "  tfkl.MaxPool2D((2,2),strides=2),\n",
    "  tfkl.Conv2D(\n",
    "      nfilters*4, (2,2),\n",
    "      padding=\"same\",\n",
    "      activation='relu'),\n",
    "  tfkl.MaxPool2D((2,2),strides=2),    \n",
    "  \n",
    "  tf.keras.layers.Flatten(),      \n",
    "  tfkl.Dense(128, activation='relu'),\n",
    "  tfkl.Dense(64, activation='relu'),\n",
    "  tfkl.Dense(64, activation='tanh'),\n",
    "  tfkl.Dense(tfpl.MixtureNormal.params_size(num_components),activation=None),\n",
    "############################################################################################\n",
    "#### Only one of the next two lines should be uncommented, keep the other one commented ####\n",
    "#### The \"Dense\" layer will output a probability per item (value between 0 & 1), while  ####\n",
    "#### the \"MixtureNormal\" will output a probability density function                     ####\n",
    "############################################################################################       \n",
    "  #tfkl.Dense(1,activation='sigmoid')\n",
    "  tfpl.MixtureNormal(num_components)\n",
    "    ])     \n",
    "\n",
    "\n",
    "  cnn.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00002),loss=negloglik)\n",
    "\n",
    "  return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain,Xval,Yval,Xtest,Ytest = train_test(3000,300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_model(16,1,256,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd0a5UgqigwH"
   },
   "source": [
    "# Exercice 2: \n",
    "Test the deep learning model on the same map, produced now with the SIMBA cosmological model. \n",
    "\n",
    "Tip: if you run out of memory, save the weights of the previous training (model.save_weights) in your GDrive , restart the notebook and load. GDrive can be mounted with the left menu.\n",
    "\n",
    "- Produce a scatter plot, including error bars, of input Omega_m versus output Omega_m. Comment.\n",
    "- Plot ten example plots of posterior distributions\n",
    "- Plot the 1-sigma value of the posterior versus the true error. Does the posterior properly capture uncertainty? Comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzrpkFoIpIC8"
   },
   "source": [
    "# Exercice 3: \n",
    "Repeat the steps above with an astrophysics parameter, e.g A_AGN_1, which parametrizes the type of AGN feedback. Compare and comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-zj5Io4vlkg"
   },
   "source": [
    "# Exercice 4 [Optional]\n",
    "\n",
    "Desing a domain adaptation technique so that the model trained on TNG can work in SIMBA."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPm7lhQcGy8sp1Ra3HnR7Mc",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Uud2sY36EWxfZpiPCT483zjZfm0OL6uw",
   "name": "ULL22_MLproject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
